# AI-Sign-Language-Translator
# ğŸ¤Ÿ AI-Powered Sign Language Translator

This project uses a Convolutional Neural Network (CNN) model trained on American Sign Language (ASL) images to translate hand gestures into real-time text using webcam input. A Streamlit web app is used to display the result with an interactive interface.

---

## ğŸ“ Folder Structure

Sign_Language_Translator/
â”‚

â”œâ”€â”€ dataset/ # ASL image dataset (not included here)

â”‚

â”œâ”€â”€ models/

â”‚ â””â”€â”€ sign_model.h5 # Trained model

â”‚

â”œâ”€â”€ src/

â”‚ â”œâ”€â”€ app.py # Streamlit web app

â”‚ â”œâ”€â”€ train_model.py # Model training script

â”‚ â”œâ”€â”€ data_preprocessing.py # Dataset loader

â”‚ â”œâ”€â”€ predict_realtime.py # OpenCV live prediction

â”‚ â””â”€â”€ text_to_speech.py # Optional TTS functionality

â”‚

â”œâ”€â”€ requirements.txt

â””â”€â”€ README.md


---

## âš™ï¸ Technologies Used

- Python ğŸ
- TensorFlow / Keras ğŸ§ 
- OpenCV ğŸ¥
- Streamlit ğŸŒ
- NumPy & scikit-learn ğŸ“Š

---

## ğŸš€ How to Run

### ğŸ”§ 1. Clone the repository

```bash
git clone https://github.com/yourusername/Sign_Language_Translator.git
cd Sign_Language_Translator
```

### ğŸ“¦ 2. Install dependencies

```bash
pip install -r requirements.txt
```

### ğŸ§  3. Train the model (optional if sign_model.h5 is already available)

```bash
python src/train_model.py
```

### ğŸŒ 4. Run Streamlit Web App

```bash
streamlit run src/app.py
```

---

## ğŸ§  Model Details

- **Input:** 64x64 RGB images  
- **Architecture:**  
  - 3 Convolutional layers + MaxPooling  
  - Dense(128) + Dropout  
  - Final layer: softmax over ASL classes  
- **Accuracy:** ~95% on test dataset

---

## ğŸ“· Example Output

![Screenshot 2025-05-31 200030](https://github.com/user-attachments/assets/34855730-572e-45f8-91e2-32744019095a)

---

## ğŸ™‹â€â™‚ï¸ Author  
**Dhruv Singh Somvanshi**
 
- ğŸ”— [LinkedIn](https://www.linkedin.com/in/dhruv-pratap-singh-459524284)

---

â­ _Star this repository if you found it useful!_


